<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<title>Improving Model Drift for Robust Object Tracking</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


	<!-- Meta tags for Zotero grab citation -->
	<meta name="citation_title" content="Improving Model Drift for Robust Object Tracking">
	<meta name="citation_author" content="Qiujie Dong">
	<meta name="citation_author" content="Xuedong He">
	<meta name="citation_author" content="Haiyan Ge">
	<meta name="citation_author" content="Qin Liu">
	<meta name="citation_author" content="Aifu Han">
	<meta name="citation_author" content="Shengzong Zhou">
	<meta name="citation_publication_date" content="2020">
	<meta name="citation_conference_title" content="Multimedia Tools and Applications">
	<meta name="citation_pdf_url" content="https://doi.org/10.1109/TVCG.2023.3259044">

	<meta name="robots" content="index,follow">
	<meta name="description"
		content="Discriminative correlation filters show excellent performance in object tracking.
		However, in complex scenes, the apparent characteristics of the tracked target are variable,
		which makes it easy to pollute the model and cause the model drift.
		In this paper, considering that the secondary peak has a greater impact on the model update,
		we propose a method for detecting the primary and secondary peaks of the response map.
		Secondly, a novel confidence function which uses the adaptive update discriminant mechanism is proposed,
		which yield good robustness. Thirdly, we propose a robust tracker with correlation filters,
		which uses hand-crafted features and can improve model drift in complex scenes.
		Finally, in order to cope with the current trackers’ multi-feature response merge,
		we propose a simple exponential adaptive merge approach.
		Extensive experiments are performed on OTB2013, OTB100 and TC128 datasets.
		Our approach performs superiorly against several state-of-the-art trackers while runs at speed in real time.
		">
    <link rel="icon" type="image/png" href="/author/icon.jpg">

	<!-- Fonts and stuff -->
	<link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800'
		rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" href="../../css/project.css" media="screen" />
	<link rel="stylesheet" type="text/css" media="screen" href="../../css/iconize.css" />
	<script src="js/google-code-prettify/prettify.js"></script>
</head>

<body>
	<div id="content">
		<div id="content-inner">
			<div class="section logos" style="text-align:center">
				<a href="https://english.cas.cn/" target="_blank"><IMG src="../Assets/logos/logo_SDU.png" height="66" border="0"></a></td>
                <a href="https://en.qust.edu.cn/" target="_blank"><IMG src="../Assets/logos/logo_QUST.png" height="66" border="0"></a></td>
                <a href="https://www.nbt.edu.cn/" target="_blank"><IMG src="../Assets/logos/logo_NBT.png" height="66" border="0"></a></td>
                <a href="https://www.tamu.edu/" target="_blank"><IMG src="../Assets/logos/logo_ATM.png" height="66" border="0"></a></td>
			</div>

			<div class="section head">

				<h1>Improving Model Drift for Robust Object Tracking</h1>

				<div class="authors">
					<a href="https://qiujiedong.github.io/" target="_blank">Qiujie Dong</a><sup> 1</sup>&#160;&#160;
                    <a href="https://scholar.google.com/citations?user=DqEP_nIAAAAJ&hl" target="_blank">Zixiong Wang</a><sup> 1</sup>&#160;&#160;
                    <a href="https://manyili12345.github.io/" target="_blank">Manyi Li</a><sup> 1</sup>&#160;&#160;
                    <a href="https://scholar.google.com/citations?user=CTDs13EAAAAJ&hl" target="_blank">Junjie Gao</a><sup> 1</sup>&#160;&#160;
                    <a href="https://ieeexplore.ieee.org/author/37088955375" target="_blank">Shuangmin Chen</a><sup> 2</sup>&#160;&#160;
                    <a href="https://ieeexplore.ieee.org/author/37086874041" target="_blank">Zhenyu Shu</a><sup> 3</sup>&#160;&#160;
                    <br>
                    <a href="http://irc.cs.sdu.edu.cn/~shiqing/index.html" target="_blank">Shiqing Xin</a><sup> 1</sup>&#160;&#160;
                    <a href="http://irc.cs.sdu.edu.cn/~chtu/index.html" target="_blank">Changhe Tu</a><sup> 1</sup>&#160;&#160;
                    <a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html" target="_blank">Wenping Wang</a><sup> 4</sup>&#160;&#160;
				</div>

				<div class="affiliations">
					<sup>1</sup><a href="https://www.en.sdu.edu.cn/" target="_blank">Shandong University</a>&#160;&#160;
					<sup>2</sup><a href="https://en.qust.edu.cn/" target="_blank">Qingdao University of Science and Technology</a>&#160;&#160;
                    <br>
					<sup>3</sup><a href="https://www.nbt.edu.cn/" target="_blank">Ningbo Institute of Technology, Zhejiang University</a>&#160;&#160;
                    <sup>4</sup><a href="https://www.tamu.edu/" target="_blank">Texas A&M University</a>&#160;&#160;
				</div>
				<div class="venue"> Multimedia Tools and Applications (CCF-C) </div>
			</div>
						<div class="section downloads">
					<center>
						<ul style="padding-left: 0">
							<li class="grid">
								<div class="griditem">
									<a href="https://arxiv.org/abs/2202.00307"><img src="../Assets/images/pdf.png"></a><br/>
									<a href="https://arxiv.org/abs/2202.00307">Paper</a>
								</div>
							</li><li class="grid">
								<div class="griditem">
									<a href="https://github.com/QiujieDong/Laplacian2Mesh"><img src="../Assets/images/github.png"></a><br/>
									<a href="https://github.com/QiujieDong/Laplacian2Mesh">Code</a>

								</div>
							</li></ul>
					</center>
				</div>


			<div class="section abstract">
				<h2>Abstract</h2><br>
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/spatial_transformations.png" style="width:85%; margin-bottom:20px">
					</div>

				</div>
				<p>
					Discriminative correlation filters show excellent performance in object tracking.
					However, in complex scenes, the apparent characteristics of the tracked target are variable,
					which makes it easy to pollute the model and cause the model drift.
					In this paper, considering that the secondary peak has a greater impact on the model update,
					we propose a method for detecting the primary and secondary peaks of the response map.
					Secondly, a novel confidence function which uses the adaptive update discriminant mechanism is proposed,
					which yield good robustness. Thirdly, we propose a robust tracker with correlation filters,
					which uses hand-crafted features and can improve model drift in complex scenes.
					Finally, in order to cope with the current trackers’ multi-feature response merge,
					we propose a simple exponential adaptive merge approach.
					Extensive experiments are performed on OTB2013, OTB100 and TC128 datasets.
					Our approach performs superiorly against several state-of-the-art trackers while runs at speed in real time.
				</p>
			</div>

			<div class="section abstract">
				<h2>Introduction</h2><br>

				<p>
					In this paper, we propose Laplacian2Mesh, inheriting the spirit of those spectral approaches,
					to make it possible to conduct learning tasks in the spectral domain when the input is a polygonal mesh.
					Note that the main technique of spectral approaches is to encode the overall shape by a subset of the
					eigenvectors decomposed from the Laplacian matrix of the input mesh.
					Two reasons account for why we advocate using the new representation in deep learning.
					First, as the low-frequency signals, given by those eigenvectors with small eigenvalues,
					encode the overall shape, they are more semantically important than high-frequency signals for most understanding tasks.
					It is easy for one to separate low-frequency signals from high-frequency signals in spectral approaches by setting a simple parameter k.
					Second, the Laplacian-based spectral transform can decouple shape variations from the tedious triangulation,
					avoiding tangling with tedious and irregular triangulations.
					Even if the input mesh contains a limited number of defects (e.g., non-manifold), the representation still works.
				</p>

				<center>
					<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/pipeline.png" style="width:85%; margin-bottom:20px">
					</div>
					<p>Pipeline of Laplacian2Mesh.
					</p>
					</div>
				</center>
				<p>
					Our network pipeline for coping with the mesh classification and segmentation tasks. Given a 3D mesh as the input,
					we precompute the extrinsic and intrinsic geometric features and project them into the spectral domain w.r.t.
					three different resolutions. Inspired by the U-Net architecture,
					we propose to use the SE-ResNet blocks with small-sized convolution kernels to fuse the nearby-frequency features,
					and the Laplacian pooling/unpooling to fuse the spectral features of different resolutions.
					For the segmentation task, we re-scale (with the yellow block) and concatenate the features together to be processed
					by the segmentation block.
				</p>

				<center>
					<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/pooling_unpooling.png" style="width:85%; margin-bottom:20px">
					</div>
					<p>Pooling and Unpooling of Laplacian2Mesh.
					</p>
					</div>
				</center>
				<p>
					The Laplacian pooling and unpooling operations transform the spectral-based features between different resolutions,
					where the pooling operation proceeds from a finer level to a coarser level while the unpooling operation does the opposite.
				</p>
			</div>

			<br>

			<div class="section abstract">
				<h2>Results</h2><br>

				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/coseg_seg.png" style="width:95%; margin-bottom:20px">
						<p>
							Gallery of segmentation results for the COSEG dataset.
							From left to right, they are Tele-aliens, Chairs, and Vases.
						</p>
					</div>

					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/humanbody_seg.png" style="width:80%; margin-bottom:20px">
						<p>
							We test the dataset of Human Body, and visualize the segmentation result for every model.
						</p>
					</div>
				</div>
			</div>

			<br>

			<div class="section abstract">
				<h2>Strengths</h2><br>
				<p>
					Laplacian2Mesh combines the geometric spectral theory with deep learning,
					which overcomes the challenges of dealing with the irregular connectivity of meshes,
					and is a promising direction to understand 3D shapes in a tessellation independent manner.
					Our network inherits some merits of spectral analysis approaches.
					First, it can encode the shape features in various levels (from local to global) and naturally has a noise-resistance ability.
					Second, it is independent of mesh resolution/tesselation and can handle non-watertight, non-manifold, and incomplete triangle-meshes.
				</p>
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/anti-noise.png" style="width:95%; margin-bottom:20px">
						<p>
							The qualitative results of testing the noise-resistance.
							As noise levels rise, segmentation outputs of DiffusionNet diverge significantly from the ground-truth,
							while ours is more in line with it. Numbers are levels of Gaussian noise added.
							<br>
							(a) DiffusionNet-hks; (b) DiffusionNet-xyz; (c) Laplacian2Mesh; (d) Laplacian2Mesh (point cloud); (e) Ground-Truth.
						</p>
					</div>

					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/un-manifold.png" style="width:95%; margin-bottom:20px">
						<p>
							Our Laplacian2Mesh is able to perform segmentation on the nonwatertight
							and non-manifold data.
							(a) and (b) are non-watertight vases and chairs,
							respectively; (c) has a non-manifold vertex, and (d) has a non-manifold edge.
						</p>
					</div>

					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/incomplete_models.png" style="width:70%; margin-bottom:20px">
						<p>
							The results on incomplete models. The red dashed boxes on the mesh indicate the deleted parts.
							The green dashed boxes highlight the inaccurate segmentation boundaries.
						</p>
					</div>

				</div>
			</div>

			<div class="section list">
				<h2>Citation</h2>
				<div class="section bibtex">
					<pre>@ARTICLE{Dong2023Laplacian2Mesh,
author={Dong, Qiujie and Wang, Zixiong and Li, Manyi and Gao, Junjie and Chen, Shuangmin and Shu, Zhenyu and Xin, Shiqing and Tu, Changhe and Wang, Wenping},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Laplacian2Mesh: Laplacian-Based Mesh Understanding},
year={2023},
pages={1-13},
doi={10.1109/TVCG.2023.3259044}}
					</pre>
				</div>
			</div>

			<div class="section">
				<hr class="smooth">
				This page is maintained by <a href="https://qiujiedong.github.io/" target="_blank">Qiujie Dong</a>.
				Latest updated on
				<script>
					document.write(new Date().toLocaleDateString())
				</script>
			</div>
		</div>
	</div>
</body>
</html>